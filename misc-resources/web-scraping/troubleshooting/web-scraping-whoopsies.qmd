---
title: "Web Scraping Whoopsies"
title-block-banner: true
author: "Manu Alcala + Jameson Carter"
date: "October 18, 2023"
format: 
    revealjs: 
        slide-number: c/t
        width: 1250
        height: 800
editor: visual
---

## What is web scraping?

static vs dynamic

scraping vs crawling

## When is it worth it?

commonly produced highly standardized data

getting data quickly is valuable

no download available, cannot get through to data provider

format remains consistent

## What makes it hard? (can be multiple slides)

takes time to code

sites might change

not always desired from site maintainers

difficulty is variable and hard to predict

# Example 1. Scraping state education sites

## Demonstrative example {video-loop="true"}

Slides describing florida example

# Example 2. Scraping Medicaid enrollment data

## Why Medicaid enrollment data?

Since Spring 2023, states have been disenrolling Medicaid beneficiaries who no longer qualify since the Public Health Emergency was ended.

::: {layout-ncol="1"}
![](kff-fig.png)
:::

## Why are the data interesting?

In anticipation, many states implemented policy changes to smooth the transition.

To understand the success of these policies, we wanted **time-series enrollment data for all 50 states**... from a Medicaid data system that is largely decentralized.

## Unreadable PDFs abound!

::: {layout-ncol="2"}
![An example from Louisiana](louisiana-horrible.png)

![and another from Ohio](ohio-horrible.png)
:::

## A sigh of relief...

Why page through PDFs when another organization's RAs can do it for you?

::: {layout-ncol="1"}
![](kff-page.png)
:::

## 1. Identify this is a scrape-able dynamic page

One URL with data you can only get by clicking each option!

::: {layout-ncol="1"}
![](kff-page-click.png)
:::

## 2. Confirm HTML actually contains the data

::: {layout-ncol="1"}
![](html-plot.png)
:::

## 3. Code for 30 hours! {#fun-slide background-video="web-surfer.mp4" background-video-loop="true" background-size="50px"}

```{css, echo=FALSE}
#fun-slide,
#fun-slide h2{
 color: blue;
 font-size: 200px;
 font-style: italic;
 font-family: cursive;
}
```

## 4. Bask in the glow of automated scraping

Whenever new data were released in the following 2 months, I re-ran the code and got a well-formatted excel file as output.

::: {layout-ncol="1"}
![](example-scraped.png)
:::

## Little did I know, trouble was coming

::: {layout-ncol="1"}
![](trouble-in-paradise.png)
:::

## What happened?

2 months later, KFF **stopped updating** the dashboard.

::: {layout-ncol="1"}
![](broken-egg.png)
:::

# Concluding remarks

## Core lessons to remember

Before coding a web scraper, think to yourself:

-   Are the data available through other routes?

-   Are the data produced by an organization that is invested in the problem long-term?

-   If scraping from a graph, what is the risk that it will be changed?

-   Is the time spent coding worth the payoff?

## Thank You!

Please contact Manu Alcala or Jameson Carter if you would like to discuss either of these projects or scoping whether a use-case is reasonable.

When you click the **Render** button a presentation will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```
