{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51877468",
   "metadata": {},
   "source": [
    "# Building a Web Scraping Workflow\n",
    "\n",
    "## Loops, Lists, and other Pythonic things!\n",
    "Now that we know how to set up the page how we want it and scrape the text that we're interested in we need to think through how to loop through each of the different combinations of variables that we're interested in. This is where things get interesting! I like to think of it as a puzzle, and we need to figure out the right order and combination of how things fit together to get it to run. \n",
    "\n",
    "Let's start with a quick review of some Python objects and syntax - and a reminder that deeper dives on all these concepts can be found in our Intro to Python series: https://ui-research.github.io/python-at-urban/content/intro-to-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb7919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 7, 9, 11, 13]\n",
      "{'a': 3, 'b': 5, 'c': 7, 'd': 9, 'e': 11, 'f': 13}\n"
     ]
    }
   ],
   "source": [
    "# Lists contain a collection of values.\n",
    "my_list = [3, 5, 7, 9, 11]\n",
    "# Dictionaries contain a collection of key, value pairs. The keys should be strings or numbers, while the values can be any data type, even lists or dictionaries themselves.\n",
    "my_dict = {'a': 3, 'b': 5, 'c': 7, 'd': 9, 'e': 11}\n",
    "# In a web scraping context, these will be helpful objects for storing data as we loop through various web page objects and append the text we extract. We can add new values like this:\n",
    "my_list.append(13)\n",
    "my_dict['f'] = 13\n",
    "\n",
    "print(my_list)\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365c826",
   "metadata": {},
   "source": [
    "Loops allow you to iterate over all values in some sort of collection (e.g. a list). There are two main types of loops in Python: for loops and while loops.\n",
    "\n",
    "For loops are probably more common for this sort of application, because we have a fixed number of iterations, but while loops can be nice when you have an indefinite number. Just be careful that the condition eventually evaluates to False, or you'll have an infinite loop!\n",
    "\n",
    "Finally, as you'll see below, loops can be nested within each other, meaning that you can have a loop within a loop. In this case, for *every* iteration of the outer loop, the inner loop would run through *all* of its iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f802c893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "1 a\n",
      "1 b\n",
      "1 c\n",
      "2 a\n",
      "2 b\n",
      "2 c\n",
      "3 a\n",
      "3 b\n",
      "3 c\n"
     ]
    }
   ],
   "source": [
    "# Loops allow you to iterate over all values in some sort of collection (e.g. a list). There are two main types of loops in Python: for loops and while loops.\n",
    "for item in my_list:\n",
    "    print(item + 1)\n",
    "\n",
    "# Example while loop\n",
    "i = 0\n",
    "while i < len(my_list):\n",
    "    print(my_list[i] + 1)\n",
    "    i += 1\n",
    "\n",
    "# Nested for loop\n",
    "list1 = [1, 2, 3]\n",
    "list2 = ['a', 'b', 'c']\n",
    "\n",
    "for i in list1:\n",
    "    for j in list2:\n",
    "        print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b8c88d",
   "metadata": {},
   "source": [
    "Last week, we learned how to set up the page how we want it and scrape the text that we're interested in. Now we need to think through how to loop through each of the different combinations of variables that we're interested in. This is where things get interesting! Think of it like a puzzle, and we need to figure out the right order and combination of how things fit together to get it to run. \n",
    "\n",
    "At this stage in the web scraping process, rather than diving straight into the code, we're going to focus on pseudo code to learn how to ** *think* ** about approaching the problem. Once you know what you want to do conceptually, the syntax is something you can either look to past examples for or look to Google/Stack Overflow for. As we introduced on week 1, concept > syntax.\n",
    "\n",
    "First, try to break the problem down into which pieces we want to change at the same time, and which we want to stay consistent. As a reminder, the project team we're working with needs the cost of the Silver Plan Premium for each county for people aged 14, 20, 40, and 60. \n",
    "\n",
    "### TASK 1 \n",
    "\n",
    "**Looking at the web page, what values need to change *every* time we want to scrape a new value, and what values only need to be set *some* of the times we want to scrape the page?** NOTE AR: What needs to change when we set a new age vs new county?\n",
    "\n",
    "\n",
    "![Full page](images/full-page.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb53b38",
   "metadata": {},
   "source": [
    "\n",
    "### TASK 1 SOLUTION\n",
    "\n",
    "<details>\n",
    "\n",
    "STATE only needs to change once we've gone through each of the ZIP CODE/COUNTY pairs in the state. And AGE changes four times for each zip code/county pair.\n",
    "\n",
    "Now that we've thought through this hierarchy, we have the three levels of nested `for` loops that we need!! \n",
    "</details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca23488",
   "metadata": {},
   "source": [
    "\n",
    "### Functional Programming\n",
    "\n",
    "\n",
    "We'll use functions to apply the code we wrote in Session 3 to our nested for loops. Some values only need to be set when the county changes, while others need to be set every time we want to get a new premium value for different ages. Therefore, we can split the `selenium` code we wrote yesterday into two functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ceda183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions saved in utils.py\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c42fd6",
   "metadata": {},
   "source": [
    "### TASK 2\n",
    "\n",
    "**Fill in the following function with `selenium` code from yesterday for the sections of the page that only need to be updated when the county changes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_page(state, driver, zipcode):\n",
    "    '''\n",
    "     This functions sets up the initial page conditions that don't need to change with each iteration through the age groups \n",
    "\n",
    "     Inputs: \n",
    "        zipcode is input to the dropdown menus on the website. \n",
    "            Each time this function is called below, it is for a different cut of the data.\n",
    "        counter (int): Counts how many times this function has been called in the script below\n",
    "        driver: Specify the driver with the web page we are navigating \n",
    "\n",
    "    Returns: \n",
    "        Nothing, just sets up the page\n",
    "     '''\n",
    "\t# function to set state, county, and income which don't change when looping through a county\n",
    "    # pring the state and zip code to the console \n",
    "    print(f'State = {state}, zip Code ={zipcode}')\n",
    "    \n",
    "    # Select state dropdown\n",
    " \n",
    "    # Enter zip code\n",
    "\n",
    "    # Enter yearly household income\n",
    "    \n",
    "    # use the is_textbox_empty() function to check if there is already a value in the income textbox\n",
    "\n",
    "        # if there isnt, enter income value of 100000\n",
    "    \n",
    "    # Is coverage available from your or your spouse's job? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5973c683",
   "metadata": {},
   "source": [
    "### TASK 2 SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea36633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_page(state, driver, zipcode):\n",
    "    '''\n",
    "     This functions sets up the initial page conditions that don't need to change with each iteration through the age groups \n",
    "\n",
    "     Inputs: \n",
    "        zipcode is input to the dropdown menus on the website. \n",
    "            Each time this function is called below, it is for a different cut of the data.\n",
    "        counter (int): Counts how many times this function has been called in the script below\n",
    "        driver: Specify the driver with the web page we are navigating \n",
    "\n",
    "    Returns: \n",
    "        Nothing, just sets up the page\n",
    "     '''\n",
    "\t# function to set state, county, and income which don't change when looping through a county\n",
    "    # pring the state and zip code to the console \n",
    "    print(f'State = {state}, zip Code ={zipcode}')\n",
    "    \n",
    "     # Select state dropdown\n",
    "    select_dropdown(identifier='//*[@id=\"state-dd\"]',driver = driver, value=state)\n",
    "    # Enter zip code\n",
    "    enter_text(identifier='//*[@id=\"zip-wrapper\"]/div/input', driver = driver, text = zipcode)\n",
    "        # if there's an option to select a county, select the county associated with the zip code\n",
    "        # Attempt to locate and click the dropdown element\n",
    "\n",
    "        # Enter yearly household income\n",
    "    if is_textbox_empty(driver=driver, textbox_id='//*[@id=\"subsidy-form\"]/div[2]/div[1]/div[2]/div[2]/input'):\n",
    "        # enter income value if the text box does not already have text \n",
    "        enter_text(identifier='//*[@id=\"subsidy-form\"]/div[2]/div[1]/div[2]/div[2]/input', driver = driver, text = '100000') # this stays the same each time\n",
    "    \n",
    "    # Is coverage available from your or your spouse's job? \n",
    "    click_button(identifier='//*[@id=\"employer-coverage-0\"]', driver = driver,) # this stays the same each time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e07095",
   "metadata": {},
   "source": [
    "In the second function, we want to set up the correct values for the age value that we're on in the loop. Note that when the age is 14 or 20, we need to set the number of adults to 0 and number of children to 1 and then select the correct age. When the age is 40 or 60, we need to do the opposite. Once all of the specifics on the page are set up, we want to use the `BeautifulSoup` code that we wrote last session to actually scrape the data. \n",
    "\n",
    "### TASK 3\n",
    "\n",
    "Fill in the function below with the appropriate  `selenium` code from the last session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6499300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(age, driver):\n",
    "     '''\n",
    "     This functions scrapes the price of the silver plan premium (without financial help) for non-smoking 14, 20, 40, and 60 year old people for each county nationally and saves it as a dataframe \n",
    "\n",
    "     Inputs: \n",
    "        age: an input to the dropdown menus on the website. \n",
    "            Each time this function is called below, it is for a different cut of the data.\n",
    "        driver: Specify the driver with the web page we are navigating \n",
    "\n",
    "    Returns: \n",
    "        The Silver Plan Premium for the specified age\n",
    "     '''\n",
    "     # print the age that we are scraping to the console\n",
    "     print(f'age = {age}')\n",
    "\n",
    "     # Number of adults (21 to 64) enrolled in Marketplace coverage? (changes based on input age)\n",
    "     if age in [ , ]: # fill in with these are the indexes for 40yo and 60yo\n",
    "        # set number of kids to 0\n",
    "\n",
    "        # set number of adults to 1\n",
    "\n",
    "        # Age? (index is age minus 21)\n",
    "\n",
    "     else: \n",
    "        # set number of adults to 0\n",
    "\n",
    "        # set number of kids to 1 \n",
    "\n",
    "        # Age\n",
    "        \n",
    "     # print update to console    \n",
    "     print('Found data download button now clicking it')\n",
    "\n",
    "     # Click submit button\n",
    "\n",
    "     print('Now scraping data')\n",
    "\n",
    "     ##--- Beautiful Soup ---###\n",
    "     # Beautiful Soup setup using the desired URL\n",
    "    \n",
    "    \n",
    "     # return scraped value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c7b72e",
   "metadata": {},
   "source": [
    "### TASK 3 SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f1ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(age, driver):\n",
    "     '''\n",
    "     This functions scrapes the price of the silver plan premium (without financial help) for non-smoking 14, 20, 40, and 60 year old people for each county nationally and saves it as a dataframe \n",
    "\n",
    "     Inputs: \n",
    "        age: an input to the dropdown menus on the website. \n",
    "            Each time this function is called below, it is for a different cut of the data.\n",
    "        driver: Specify the driver with the web page we are navigating \n",
    "\n",
    "    Returns: \n",
    "        The Silver Plan Premium for the specified age\n",
    "     '''\n",
    "     # print the age that we are scraping to the console\n",
    "     print(f'age = {age}')\n",
    "\n",
    "     # Number of adults (21 to 64) enrolled in Marketplace coverage? (changes based on input age)\n",
    "     if age in [19 ,39]: # fill in with these are the indexes for 40yo and 60yo\n",
    "        # set number of kids to 0\n",
    "        select_dropdown(identifier='//*[@id=\"subsidy-form\"]/div[2]/div[3]/div[3]/div/select',driver = driver, index = '0')\n",
    "        # set number of adults to 1\n",
    "        select_dropdown(identifier='//*[@id=\"subsidy-form\"]/div[2]/div[3]/div[1]/div/select',driver = driver, value = \"1\")\n",
    "        # Age? (index is age minus 21)\n",
    "        select_dropdown(identifier='//*[@id=\"subsidy-form\"]/div[2]/div[3]/div[2]/div/div[1]/select', driver = driver,index = age)\n",
    "     else: \n",
    "        # set number of adults to 0\n",
    "        select_dropdown(identifier='//*[@id=\"subsidy-form\"]/div[2]/div[3]/div[1]/div/select',driver = driver, value = \"0\")\n",
    "        # Number of children (20 and younger) enrolling in Marketplace coverage\n",
    "        select_dropdown(identifier='//*[@id=\"subsidy-form\"]/div[2]/div[3]/div[3]/div/select',driver = driver, index = '1')\n",
    "        select_dropdown(identifier='//*[@id=\"subsidy-form\"]/div[2]/div[3]/div[4]/div/div[1]/select',driver = driver, index = age)\n",
    "        \n",
    "     # print update to console    \n",
    "     print('Found data download button now clicking it')\n",
    "     # Submit\n",
    "     click_button(identifier='//*[@id=\"subsidy-form\"]/p/input[2]', driver = driver,)\n",
    "\n",
    "     time.sleep(1)       \n",
    "     print('Now scraping data')\n",
    "\n",
    "     ##--- Beautiful Soup ---###\n",
    "     # Beautiful Soup setup using the desired URL\n",
    "     html = driver.page_source\n",
    "     soup = BeautifulSoup(html, 'html.parser') #Another parsing option is 'lxml' which we talked about in week 2\n",
    "     \n",
    "     premium_val = str(soup.find_all('span', class_ = \"bold-blue\")[4])# select the 4th element which has the value we want \n",
    "\n",
    "     \n",
    "     extracted_number = re.search(r'\\$([\\d,]+(?:\\.\\d{1,2})?)', premium_val)\n",
    "     \n",
    "    # Extract the matched group (number with $ and commas)\n",
    "     matched_string = extracted_number.group(0)\n",
    "    # Remove $ and commas from the matched string\n",
    "     clean_number = matched_string.replace('$', '').replace(',', '')\n",
    "    # Convert the cleaned string to a numeric value (float or int)\n",
    "     number = float(clean_number) \n",
    "     print(number)\n",
    "        \n",
    "     return (number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e5c3d7",
   "metadata": {},
   "source": [
    "## Iterating over options on the website\n",
    "\n",
    "Let's read in a CSV file with the states, counties, and zip codes that we want to scrape. This will just be a set of 10 to keep things simple. We can then convert it to a list of lists (aka a nested list) to make it even easier to iterate over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f5d3d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['co', 'Kit Carson', 80805],\n",
       " ['ga', 'Dooly', 31007],\n",
       " ['il', 'Marion', 62801],\n",
       " ['il', 'Kane', 60109],\n",
       " ['ks', 'Harvey', 67020],\n",
       " ['ky', 'Bourbon', 40348],\n",
       " ['md', 'Wicomico', 21801],\n",
       " ['mo', 'Buchanan', 64401],\n",
       " ['ok', 'Pawnee', 74020],\n",
       " ['sc', 'Abbeville', 29620]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read in CSV with states, counties, zips and sort by state\n",
    "zip_data_small = pd.read_csv('data/zip_data_small.csv').sort_values('state_abbr')\n",
    "# Convert df to list of lists\n",
    "zip_data_small_list = zip_data_small.values.tolist()\n",
    "zip_data_small_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf966ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['co', 'Kit Carson', 80805]\n",
      "co\n"
     ]
    }
   ],
   "source": [
    "# Print the first state/county/zip combo\n",
    "print(zip_data_small_list[0])\n",
    "# Print just the first state in the list\n",
    "print(zip_data_small_list[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03a0f",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "Now that we have functions to 1) set up sections of the page that need to update for every county, and 2) set up what needs to change for different ages and scrape the value, we can put all of the pieces together. As a reminder, at a high-level, we want to:\n",
    "\n",
    "1) Initialize a web driver\n",
    "2) Initialize and empty dictionary to capture the values that we want to scrape \n",
    "3) Specify the ages and state/counties that we want to loop over\n",
    "4) Loop over each state\n",
    "5) Loop over each county\n",
    "6) Loop over each age we need\n",
    "7) Save the output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df90ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch driver\n",
    "url = \"https://www.kff.org/interactive/subsidy-calculator/\"\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(url)\n",
    "\n",
    "# initialize empty dictionary to capture the scraped values\n",
    "premium_val_dict = {} \n",
    "# indexes for 14, 20, 40, and 60 years\n",
    "age_values = [14, 20, 19, 39] \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c17e24d",
   "metadata": {},
   "source": [
    "### TASK 4\n",
    "Now that we have the nested for loops, where would you place each of the functions we defined above? NOTE AR - Fix loops in task 4 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each state and county combo in the state nested dict\n",
    "for state, counties in state_counties_zipcodes.items():\n",
    "\n",
    "# loop through county, zip pairs\n",
    "    for county, zip_code in counties.items():\n",
    "            \n",
    "        # loop through ages we want to get premium values for\n",
    "        for age in age_values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85ee6d4",
   "metadata": {},
   "source": [
    "### TASK 4 SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each state and county combo in the state nested dict\n",
    "for state, counties in state_counties_zipcodes.items():\n",
    "\n",
    "# loop through county, zip pairs\n",
    "    for county, zip_code in counties.items():\n",
    "\n",
    "        # call the setup_page function to set top dropdown values on page\n",
    "        setup_page(state=state, driver = driver, zipcode=zip_code)\n",
    "            \n",
    "        # loop through ages we want to get premium values for\n",
    "        for age in age_values:\n",
    "\n",
    "            # call the scrape_data function to get the premium value \n",
    "            number = scrape_data(age = age, driver = driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f360060",
   "metadata": {},
   "source": [
    "### TASK 5\n",
    "\n",
    "Almost there!!! Now that we have everything in place to scape the data, we need to think about how to store the premium plan values that we did all of this work to get! To do that, again we need to think about what is happening at each step in our nested for loops and where the best place to save the data is. Within the age for loop, we want to capture all of the scraped values in a list called `premium_val_list`. And then we want to save that list with the county and state that it came from in the dictionary that we initialized at the beginning called `premium_val_dict`.\n",
    "\n",
    "Try to fill in those items where they belong in the skeleton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a00333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('ky', {'Bourbon': '40348'}), ('il', {'Marion': '62801', 'Kane': '60109'}), ('ok', {'Pawnee': '74020'}), ('ks', {'Harvey': '67020'}), ('mo', {'Buchanan': '64401'}), ('ga', {'Dooly': '31007'}), ('sc', {'Abbeville': '29620'}), ('co', {'Kit Carson': '80805'}), ('md', {'Wicomico': '21801'})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each state and county combo in the state nested dict\n",
    "for state, counties in state_counties_zipcodes.items():\n",
    "# loop through county, zip pairs\n",
    "    for county, zip_code in counties.items():\n",
    "\n",
    "        # call the setup_page function to set top dropdown values on page\n",
    "        setup_page(state=state, driver = driver, zipcode=zip_code)\n",
    "            \n",
    "        # loop through ages we want to get premium values for\n",
    "        for age in age_values:\n",
    "\n",
    "            # call the scrape_data function to get the premium value \n",
    "            number = scrape_data(age = age, driver = driver)\n",
    "                  \n",
    "# Save the dictionary as a JSON file at the end of each loop\n",
    "output_filename = f'data/output.json'\n",
    "with open(output_filename, 'w') as json_file:\n",
    "    json.dump(premium_val_dict, json_file, indent=2)  # 'indent' for pretty formatting (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518bb60",
   "metadata": {},
   "source": [
    "### TASK 5 SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9804b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for each state and county combo in the state nested dict\n",
    "for state, counties in state_counties_zipcodes.items():\n",
    "# loop through county, zip pairs\n",
    "    for county, zip_code in counties.items():\n",
    "    # initialize empty list to store premium plan values for \n",
    "    # the county that we're on in the loop \n",
    "        premium_val_list = []\n",
    "\n",
    "        # call the setup_page function to set top dropdown values on page\n",
    "        setup_page(state=state, driver = driver, zipcode=zip_code)\n",
    "            \n",
    "        # loop through ages we want to get premium values for\n",
    "        for age in age_values:\n",
    "\n",
    "            # call the scrape_data function to get the premium value \n",
    "            number = scrape_data(age = age, driver = driver)\n",
    "\n",
    "            # for each zipcode, create a list of all of the premium plan costs for each age\n",
    "            # this will be saved with the zipcode key in the dictionary\n",
    "            premium_val_list.append(number)\n",
    "                  \n",
    "        # at the end of looping through all ages in the zip code add premium values to dictionary\n",
    "        # note that this step is outside of the age for loop \n",
    "        premium_val_dict[county] = premium_val_list \n",
    "\n",
    "# Save the dictionary as a JSON file at the end of each loop\n",
    "output_filename = f'data/output.json'\n",
    "with open(output_filename, 'w') as json_file:\n",
    "    json.dump(premium_val_dict, json_file, indent=2)  # 'indent' for pretty formatting (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7bcb3",
   "metadata": {},
   "source": [
    "## Quality Assurance\n",
    "We'd like to end on a note about quality assurance. Unlike a traditional code review process at Urban, if the web scraping task runs for a very long time, a reviewer is not going to feasibly replicate everything you've done. Of course, errors in the code can still be caught, but we want to emphasize that even more than normal, it's crucial to quality check your own results. A few questions to ask yourself after you finish putting together the type of workflow we just walked through:\n",
    "\n",
    "- **Have I gone through *every* iteration?** Do the math on how many files or values or iterations you expect to run in total and make sure you have that many outputs.\n",
    "- **Are there edge cases that I might be missing?** We will see more examples of this next week, and you will see how much exceptions vary by use case! It's not feasible to check every single combination of options, but this is where the project team's domain knowledge can be key (and also probably the hardest thing for them to catch without your help).\n",
    "- **Does the resulting text or data output seem sensible?** Another place where project team input can be helpful. \n",
    "- **Have I commented my code clearly to outline my assumptions?** This one is as much for future-you as it is for anyone else. Relatedly...\n",
    "- **Have I added print statements within my workflow?** This isn't always necessary but can be incredibly helpful for tracking which iteration you're on, seeing any logic your code might be skipping over or incorrectly processing, and just generally making your code easier to understand and debug."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
